# 编译器和解析器：V8是如何执行一段JavaScript代码的

> **2025 更新说明**：本文最初撰写时，V8 的执行流水线主要由解释器 Ignition 和优化编译器 TurboFan 两层构成。近年来 V8 团队持续演进架构，先后引入了 Sparkplug（2021，基线编译器）和 Maglev（2023，中层优化编译器），形成了如今的四层编译流水线。本次更新同步补充了 WebAssembly 在 V8 中的执行路径、现代解析优化技术，以及前端工具链的最新变化，以帮助读者建立与当前 V8 实现一致的知识体系。

前面我们已经花了很多篇幅来介绍 JavaScript 是如何工作的，了解这些内容能帮助你从底层理解 JavaScript 的工作机制，从而能帮助你更好地理解和应用 JavaScript。

今天这篇文章我们就继续"向下"分析，站在 JavaScript 引擎 V8 的视角，来分析 JavaScript 代码是如何被执行的。

前端工具和框架的自身更新速度非常快，而且还不断有新的出现。要想追赶上前端工具和框架的更新速度，你就需要抓住那些本质的知识，然后才能更加轻松地理解这些上层应用。比如我们接下来要介绍的 V8 执行机制，能帮助你从底层了解 JavaScript，也能帮助你深入理解语言转换器 Babel（及其新一代替代方案 SWC、esbuild）、语法检查工具 ESLint、前端框架 Vue 和 React 的一些底层实现机制。因此，了解 V8 的编译流程能让你对语言以及相关工具有更加充分的认识。

要深入理解 V8 的工作原理，你需要搞清楚一些概念和原理，比如接下来我们要详细讲解的编译器（Compiler）、解析器（Interpreter）、抽象语法树（AST）、字节码（Bytecode）、即时编译器（JIT）等概念，都是你需要重点关注的。

## 编译器和解释器

之所以存在编译器和解释器，是因为机器不能直接理解我们所写的代码，所以在执行程序之前，需要将我们所写的代码"翻译"成机器能读懂的机器语言。按语言的执行流程，可以把语言划分为编译型语言和解释型语言。

编译型语言在程序执行之前，需要经过编译器的编译过程，并且编译之后会直接保留机器能读懂的二进制文件，这样每次运行程序时，都可以直接运行该二进制文件，而不需要再次重新编译了。比如 C/C++、GO 等都是编译型语言。

而由解释型语言编写的程序，在每次执行时都需要通过解释器对程序进行动态解释和执行。比如 Python、JavaScript 等都属于解释型语言。

那编译器和解释器是如何"翻译"代码的呢？具体流程你可以参考下图：

![编译器和解释器翻译代码](./img/translate-code.png)

从图中你可以看出这二者的执行流程，大致可阐述为如下：

1. 在编译型语言的编译过程中，编译器首先会依次对源代码进行词法分析、语法分析，生成抽象语法树（AST），然后是优化代码，最后再生成处理器能够理解的机器码。如果编译成功，将会生成一个可执行的文件。但如果编译过程发生了语法或者其他的错误，那么编译器就会抛出异常，最后的二进制文件也不会生成成功。

2. 在解释型语言的解释过程中，同样解释器也会对源代码进行词法分析、语法分析，并生成抽象语法树（AST），不过它会再基于抽象语法树生成字节码，最后再根据字节码来执行程序、输出结果。

## V8是如何执行一段JavaScript代码的

通过上面的介绍，相信你已经了解编译器和解释器了。那接下来，我们就重点分析下 V8 是如何执行一段 JavaScript 代。你可以先来"一览全局"，参考下图：

![V8执行一段代码流程图](./img/v8-execute-code-process.png)

从图中可以清楚地看到，V8 在执行过程中既有解释器 Ignition，又有编译器 TurboFan，那么它们是如何配合去执行一段 JavaScript 代码的呢？下面我们就按照上图来一一分解其执行流程。

### 1.生成抽象语法树（AST）和执行上下文

将源代码转换为抽象语法树，并生成执行上下文，而执行上下文我们在前面的文章中已经介绍过很多了，主要是代码在执行过程中的环境信息。

那么下面我们就得重点讲解下抽象语法树（下面表述中就直接用它的简称 AST 了），看看什么是 AST 以及 AST 的生成过程是怎样的。

高级语言是开发者可以理解的语言，但是让编译器或者解释器来理解就非常困难了。对于编译器或者解释器来说，它们可以理解的就是 AST 了。所以无论你使用的是解释型语言还是编译型语言，在编译过程中，它们都会生成一个 AST。这和渲染引擎将 HTML 格式文件转换为计算机可以理解的 DOM 树的情况类似。

你可以结合下面这段代码来直观地感受下什么是 AST：

```js
var myName = '极客时间'
function foo() {
  return 23
}
myName = 'geektime'
foo()
```

这段代码经过 javascript-ast 站点处理后，生成的 AST 结构如下：

![ast结构图](./img/ast-structure.png)

从图中可以看出，AST 的结构和代码的结构非常相似，其实你也可以把 AST 看成代码的结构化的表示，编译器或者解释器后续的工作都需要依赖于 AST，而不是源代码。

AST 是非常重要的一种数据结构，在很多项目中有着广泛的应用。其中最著名的一个项目是 Babel。Babel 是一个被广泛使用的代码转码器，最初以"将 ES6 代码转换为 ES5 代码"而闻名。但在现代前端开发中，Babel 的角色已经发生了显著变化：

- **面向现代环境**：随着主流浏览器对 ES6+ 的支持日趋完善，Babel 现在更多地用于转换尚未被广泛支持的最新 ECMAScript 提案语法（如 Stage 2/3 提案），以及处理 JSX（React 语法）等非标准扩展，而不再需要将所有 ES6 代码降级为 ES5。
- **TypeScript 编译**：Babel 也支持剥离 TypeScript 类型注解（Type Stripping），将 `.ts`/`.tsx` 文件转换为纯 JavaScript。Node.js 22.6+ 甚至已内置了实验性的类型剥离能力，不再强制依赖额外的编译步骤。
- **更快的替代方案**：近年来，社区出现了基于系统级语言构建的新一代编译工具，在性能上远超 Babel：
  - **SWC**（Speedy Web Compiler）：使用 Rust 编写，提供与 Babel 兼容的转换能力，速度提升可达 20-70 倍。Next.js 已默认使用 SWC 替代 Babel。
  - **esbuild**：使用 Go 编写，主打极速打包与转译，被 Vite 等现代构建工具用作开发服务器的核心转译引擎。

尽管工具在更新换代，但它们的核心工作原理并没有变化——都是先将源码转换为 AST，在 AST 层面进行转换操作，最后再从 AST 生成目标代码。理解 AST 这一概念，你就抓住了所有这些工具的共性。

除了 Babel 外，还有 ESLint 也使用 AST。ESLint 是一个用来检查 JavaScript 编写规范的插件，其检测流程也是需要将源代码转换为 AST，然后再利用 AST 来检查代码规范化的问题。

现在你知道了什么是 AST 以及它的一些应用，那接下来我们再来看下 AST 是如何生成的。通常，生成 AST 需要经过两个阶段。

**第一阶段是分词（tokenize），又称为词法分析**，其作用是将一行行的源码拆解成一个个 token。所谓 token，指的是语法上不可能再分的、最小的单个字符或字符串。你可以参考下图来更好地理解什么是 token。

![分解token示意图](./img/token-sketch.png)

从图中可以看出，通过 `var myName = '极客时间'` 简单地定义了一个变量，其中关键字 var、标识符 myName、赋值运算符 =、字符串"极客时间"四个都是token，而且它们代表的属性还不一样。

**第二阶段是解析（parse），又称为语法分析**，其作用是将上一步生成的 token 数据，根据语法规则转为 AST。如果源码符合语法规则，这一步就会顺利完成。但如果源码存在语法错误，这一步就会终止，并抛出一个"语法错误"。

这就是 AST 的生成过程，先分词，再解析。

有了 AST 后，那接下来 V8 就会生成该段代码的执行上下文。至于执行上下文的具体内容，你可以参考前面几篇文章的讲解。

### 2.生成字节码

有了 AST 和执行上下文后，那接下来的第二步，解释器 Ignition 就登场了，它会根据 AST 生成字节码，并解释执行字节码。

其实一开始 V8 并没有字节码，而是直接将 AST 转换为机器码，由于执行机器码的效率是非常高效的，所以这种方式在发布后的一段时间内运行效果是非常好的。但是随着 Chrome 在手机上的广泛普及，特别是运行在 512M 内存的手机上，内存占用问题也暴露出来了，因为 V8 需要消耗大量的内存来存放转换后的机器码。为了解决内存占用问题，V8 团队大幅重构了引擎架构，引入字节码，并且抛弃了之前的编译器，最终花了将近四年的时间，实现了现在的这套架构。

那什么是字节码呢？为什么引入字节码就能解决内存占用问题呢？

字节码就是介于 AST 和机器码之间的一种代码。但是与特定类型的机器码无关，字节码需要通过解释器将其转换为机器码后才能执行。

理解了什么是字节码，我们再来对比看下高级代码、字节码和机器码，你可以参考下图：

![字节码和机器码占用空间对比](./img/bytecode-machinecode-contrast.png)

从图中可以看出，机器码所占用的空间远远超过了字节码，所以使用字节码可以减少系统的内存使用。

### 3.执行代码：从两层到四层编译流水线

生成字节码之后，接下来就要进入执行阶段了。

在 V8 最初引入 Ignition 和 TurboFan 时，执行流水线是两层的——解释器直接配合顶层优化编译器。但从字节码直接跳到完全优化的机器码之间有一个很大的"性能悬崖"：函数在被 TurboFan 编译之前只能以解释模式执行，而 TurboFan 的编译开销又比较大，不可能对所有函数都进行优化。为了解决这个问题，V8 团队先后引入了 **Sparkplug** 和 **Maglev**，形成了如今的**四层编译流水线**：

**第一层：Ignition（解释器）**

Ignition 负责将 AST 转换为字节码，并逐条解释执行。它是所有 JavaScript 代码的入口——无论代码是否热点，都会首先经过 Ignition。Ignition 在执行过程中会收集类型反馈信息（Type Feedback），这些信息对后续的编译器至关重要。

**第二层：Sparkplug（基线编译器，2021 年引入）**

Sparkplug 是一个极其轻量的基线编译器。它的核心设计思想是：**直接从 Ignition 的字节码生成本地机器码，几乎不做任何优化**。这使得它的编译速度极快（通常在毫秒级完成），填补了"解释执行"和"完全优化"之间的性能空白。

Sparkplug 的关键特点：
- **不构建中间表示（IR）**：它直接遍历字节码，对每一条字节码指令产生对应的机器码，因此编译速度几乎与解析字节码本身一样快。
- **复用 Ignition 的栈帧布局**：Sparkplug 生成的代码与 Ignition 共享相同的栈帧结构，这意味着两者之间的切换开销极低。
- **不做推测性优化**：不同于 TurboFan，Sparkplug 不依赖类型反馈来生成特化代码，因此它生成的代码不会因为类型假设错误而需要"去优化"（Deoptimization）。

你可以把 Sparkplug 理解为一个"快速翻译器"——它把字节码忠实地翻译成机器码，去掉了解释器的调度开销，但不做任何花哨的优化。这一层带来的性能提升通常在 5%-15% 之间。

**第三层：Maglev（中层优化编译器，2023 年引入）**

Maglev 是 V8 在 Sparkplug 和 TurboFan 之间新增的一个中层优化编译器，名字来源于磁悬浮列车（Maglev Train），寓意着快速而平稳的加速。

Maglev 的设计目标是：**用较低的编译成本，获得接近 TurboFan 的大部分性能收益**。它利用 Ignition 收集的类型反馈信息进行推测性优化，但生成代码的过程比 TurboFan 简单得多——Maglev 使用基于 SSA（静态单赋值）的图形 IR，但跳过了 TurboFan 中很多昂贵的优化 pass（如逃逸分析、循环优化等）。

实践证明，Maglev 能在约 TurboFan 十分之一的编译时间内，达到其约 80% 的峰值性能。对于那些"温热"（warm）但还没有热到值得 TurboFan 编译的函数，Maglev 是一个理想的折中选择。

**第四层：TurboFan（顶层优化编译器）**

TurboFan 仍然是 V8 的顶层优化编译器。它会对真正的热点代码进行激进的推测性优化，包括内联（Inlining）、逃逸分析（Escape Analysis）、冗余消除、循环优化等高级技术。TurboFan 生成的代码质量最高，但编译成本也最大。

当类型反馈与运行时的实际类型不匹配时，TurboFan（以及 Maglev）生成的优化代码需要进行**去优化（Deoptimization）**——即放弃优化后的机器码，回退到 Ignition 解释执行，重新收集类型信息后再尝试优化。

**完整的执行路径如下**：

```
源代码 → 解析 → AST → Ignition（字节码 + 解释执行）
                          ↓ 所有函数
                      Sparkplug（基线本地代码）
                          ↓ 温热函数（基于类型反馈）
                      Maglev（中层优化代码）
                          ↓ 热点函数（进一步优化）
                      TurboFan（顶层优化代码）
```

V8 的解释器和编译器的取名也很有意思。解释器 Ignition 是点火器的意思，编译器 TurboFan 是涡轮增压的意思，Sparkplug 是火花塞的意思，Maglev 是磁悬浮的意思——整个流水线就像一辆跑车的动力系统：点火器启动引擎，火花塞让燃料燃烧，磁悬浮让速度平稳上升，涡轮增压器则在高速区间榨取最后的性能。

其实字节码配合解释器和编译器是最近一段时间很火的技术，比如 Java 和 Python 的虚拟机也都是基于这种技术实现的，我们把这种技术称为即时编译（JIT）。具体到 V8，就是指解释器 Ignition 在解释执行字节码的同时，收集代码信息，当它发现某一部分代码变热了之后，Sparkplug 首先快速编译出基线代码，随后如果代码持续升温，Maglev 和 TurboFan 编译器便依次介入，把热点的字节码转换为越来越高效的机器码，并把转换后的机器码保存起来，以备下次使用。

### 其他 JavaScript 引擎的多层编译架构

值得一提的是，这种多层编译的思路并非 V8 独创，其他主流 JavaScript 引擎也采用了类似的分层策略：

**Mozilla SpiderMonkey（Firefox）**：

SpiderMonkey 同样经历了多次架构演进。其当前的编译流水线为：
- **Baseline Interpreter**（基线解释器）→ **Baseline Compiler**（基线编译器）→ **WarpMonkey**（优化编译器）
- WarpMonkey 于 2020 年取代了原来的 IonMonkey 优化编译器。WarpMonkey 的核心改进是直接基于 Baseline Interpreter 收集的 CacheIR（缓存中间表示）来构建优化 IR，而不是像 IonMonkey 那样依赖单独的类型推断系统，从而在编译速度和代码质量之间取得了更好的平衡。

**Apple JavaScriptCore（Safari）**：

JavaScriptCore（简称 JSC）是所有主流引擎中分层最多的，拥有四层执行层级：
- **LLInt**（Low Level Interpreter，低层级解释器）→ **Baseline**（基线编译器）→ **DFG**（Data Flow Graph，中层优化编译器）→ **FTL**（Faster Than Light，顶层优化编译器）
- 这种四层架构的设计哲学与 V8 的演进方向不谋而合：在启动速度和峰值性能之间提供多个层级的渐进式优化。

这么多语言的工作引擎都使用了 `字节码+JIT` 技术，因此理解 JIT 这套工作机制还是很有必要的。你可以结合下图看看 JIT 的工作过程：

![JIT的工作过程](./img/jit-process.png)

## 现代解析优化技术

前面我们介绍了 V8 的编译流水线，但实际上在代码进入 Ignition 之前，V8 在解析阶段也做了大量的优化工作。这些优化对页面的启动速度至关重要。

### 惰性解析（Lazy Parsing）

在实际的 Web 应用中，通常加载的 JavaScript 代码量远大于启动时实际执行的代码量——研究表明，页面加载的 JavaScript 中只有约 30%-50% 会在启动阶段被执行。如果 V8 对所有代码都进行完整的解析（Full Parsing），会浪费大量的时间和内存。

为此，V8 引入了**惰性解析（Lazy Parsing）**，也称为**预解析（Pre-Parsing）**机制：

- **完整解析（Eager Parsing）**：对立即需要执行的顶层代码进行完整解析，生成 AST 和字节码。
- **预解析（Pre-Parsing）**：对于函数声明（但不立即调用）的代码，V8 使用一个轻量级的**预解析器（PreParser）**快速扫描一遍。预解析器不会生成 AST，只做以下几件事：
  - 验证语法的正确性
  - 识别函数的作用域信息和变量声明
  - 检测是否存在语法错误
  - 记录函数的起止位置

当预解析过的函数在后续被真正调用时，V8 才会对其进行完整解析、生成 AST 和字节码。这种"按需解析"的策略可以显著减少启动阶段的解析时间和内存消耗。

需要注意的一个陷阱是**立即调用的函数表达式（IIFE）**。如果一个函数被声明后立即调用，V8 的预解析反而会造成额外的开销——因为预解析完之后又立刻需要完整解析。V8 通过启发式规则（例如检测函数前的 `!` 或 `(` 符号）来尽量避免对 IIFE 进行不必要的预解析。

### 流式编译（Streaming Compilation）

传统的脚本加载方式是：先完整下载脚本文件，然后在主线程上解析和编译。但对于大型脚本，这会导致用户等待时间过长。

V8 的**流式编译**允许在脚本仍在网络下载的过程中就开始解析和编译：

- 当脚本数据的网络数据包（chunk）到达时，V8 会在一个后台线程上开始对已到达的部分进行解析。
- 这意味着当脚本下载完成时，解析工作可能已经接近完成，大大减少了从下载完成到代码可执行之间的延迟。
- 流式编译通过 `<script>` 标签的正常加载和 `fetch()` / Service Worker 等方式加载的脚本都可以受益。

### 代码缓存与字节码缓存（Code Caching）

如果用户多次访问同一个页面，每次都重新解析和编译相同的 JavaScript 代码显然是浪费的。V8 通过**代码缓存**机制来解决这个问题：

- **首次访问**：V8 正常解析、编译脚本并生成字节码。
- **二次访问**（warm run）：V8 将生成的字节码序列化并存储到磁盘缓存中（通过 Chrome 的 HTTP 缓存机制）。
- **后续访问**（hot run）：V8 直接从缓存中反序列化字节码，跳过解析和编译过程，直接进入执行阶段。

字节码缓存带来的性能提升非常显著——对于大型脚本，解析和编译时间可以减少 40% 以上。配合 Service Worker，开发者甚至可以主动控制脚本的缓存策略，进一步优化重复访问的性能。

这三项技术——惰性解析、流式编译和代码缓存——共同构成了 V8 在解析阶段的核心优化策略，对真实 Web 应用的启动性能有着至关重要的影响。

## WebAssembly 与 V8

随着 Web 应用对计算性能要求的日益提高，WebAssembly（简称 Wasm）已经成为浏览器中不可忽视的重要技术。V8 对 WebAssembly 有着原生的支持，且其执行路径与 JavaScript 有着本质的区别。

### Wasm 在 V8 中的编译流水线

不同于 JavaScript 需要经过词法分析、语法分析、AST 生成、字节码生成等一系列步骤，WebAssembly 模块是**预编译的二进制格式**，它完全跳过了 JavaScript 的解析流水线。V8 为 Wasm 提供了专门的两层编译架构：

**Liftoff（基线 Wasm 编译器）**

Liftoff 是 V8 的 Wasm 基线编译器，其设计理念与 Sparkplug 类似——追求极快的编译速度，尽快让代码跑起来：

- Liftoff 采用**单遍（single-pass）**编译策略，在遍历 Wasm 字节码的同时直接生成机器码。
- 它不构建中间表示，也不做寄存器分配优化，而是使用简单的栈机模型。
- 编译速度通常能达到每秒数十 MB 的 Wasm 字节码吞吐量。

**TurboFan（优化 Wasm 编译器）**

是的，TurboFan 同时担任了 JavaScript 和 WebAssembly 的顶层优化编译器。对于 Wasm 代码，TurboFan 会进行包括寄存器分配、指令选择、循环优化等在内的完整优化，生成高质量的机器码。

Wasm 的编译流水线同样支持**流式编译**——在 Wasm 模块下载的同时，Liftoff 就开始在后台线程上进行编译。当模块下载完成时，Liftoff 的编译通常也已经完成，用户几乎感知不到编译延迟。与此同时，TurboFan 在后台继续对热点函数进行重新编译和替换（称为 Tier-Up），逐步提升执行效率。

### Wasm 与 JavaScript 的互操作

WebAssembly 并不是要替代 JavaScript，而是作为补充：

- Wasm 擅长处理计算密集型任务（如图像处理、音视频编解码、物理模拟、加密运算等）。
- JavaScript 则更擅长处理 DOM 操作、事件处理、网络请求等 Web API 交互。
- 两者可以通过 `WebAssembly.instantiate()` 等 API 进行互调用，V8 在内部对这种跨语言调用做了优化，减少了调用边界的开销。

理解 Wasm 在 V8 中的执行路径，有助于你在面对高性能需求时做出正确的技术选型。

## JavaScript的性能优化

到这里相信你现在已经了解 V8 是如何执行一段 JavaScript 代码的了。在过去几年中，JavaScript 的性能得到了大幅提升，这得益于 V8 团队对解释器和编译器的不断改进和优化。

虽然在 V8 诞生之初，也出现过一系列针对 V8 而专门优化 JavaScript 性能的方案，比如隐藏类、内联缓存等概念都是那时候提出来的。不过随着 V8 的架构调整（特别是 Sparkplug 和 Maglev 的引入，填补了执行速度的中间层），你越来越不需要这些微优化策略了，相反，对于优化 JavaScript 执行效率，你应该将优化的中心聚集在单次脚本的执行时间和脚本的网络下载上，主要关注以下几点内容：

- 提升单次脚本的执行速度，避免 JavaScript 的长任务霸占主线程，这样可以使得页面快速响应交互。

- 避免大的内联脚本，因为在解析 HTML 的过程中，解析和编译也会占用主线程。

- 减少 JavaScript 文件的容量，因为更小的文件会提升下载速度，并且占用更低的内存。

- **善用代码分割（Code Splitting）**：将应用拆分为按需加载的小块，配合 V8 的惰性解析和流式编译，可以显著缩短首屏可交互时间（TTI）。

- **关注 Core Web Vitals**：现代性能优化更注重用户体验指标，如 INP（Interaction to Next Paint）取代了 FID（First Input Delay），要求你不仅关注首次加载，更要关注整个交互过程中的响应速度。

- **考虑 WebAssembly**：对于计算密集型逻辑（如数据处理、图形渲染），使用 Wasm 可以获得接近原生的执行性能，同时避免 JavaScript 的 JIT 编译开销。

## 总结

好了，今天就讲到这里，下面我来总结下今天的内容。

- 首先我们介绍了编译器和解释器的区别。

- 紧接着又详细分析了 V8 是如何执行一段 JavaScript 代码的：V8 依据 JavaScript 代码生成 AST 和执行上下文，再基于 AST 生成字节码，然后通过 Ignition 解释执行字节码，通过 Sparkplug 快速编译为基线机器码，通过 Maglev 进行中层优化，最终通过 TurboFan 对热点代码进行顶层优化编译——形成了完整的四层编译流水线。

- 我们还介绍了其他主流引擎（SpiderMonkey、JavaScriptCore）的多层编译架构，以及 Babel 和新一代编译工具（SWC、esbuild）的最新发展。

- 基于字节码和编译器，我们又介绍了 JIT 技术。

- 我们深入探讨了 V8 的现代解析优化技术，包括惰性解析、流式编译和代码缓存。

- 我们还分析了 WebAssembly 在 V8 中的执行路径，了解了 Liftoff 和 TurboFan 在 Wasm 编译中的角色。

- 最后我们延伸说明了下优化 JavaScript 性能的一些策略。

- 之所以在本专栏里讲 V8 的执行流程，是因为我觉得编译器和解释器的相关概念和理论对于程序员来说至关重要，向上能让你充分理解一些前端应用的本质，向下能打开计算机编译原理的大门。通过这些知识的学习能让你将很多模糊的概念关联起来，使其变得更加清楚，从而扩宽视野，上升到更高的层次。
